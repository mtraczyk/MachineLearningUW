{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "D. Convolutional (Denoising) AutoEncoders.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.set_printoptions(threshold=sys.maxsize)"
      ],
      "metadata": {
        "id": "WDtqzyR08XMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_lightning"
      ],
      "metadata": {
        "id": "AyP7kV277z44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "\n",
        "from pytorch_lightning.loggers import TensorBoardLogger"
      ],
      "metadata": {
        "id": "wY-EGraD72po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "batch_size = (...)\n",
        "lr = (...)\n",
        "device = \"gpu\""
      ],
      "metadata": {
        "id": "svpcKp546cgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_noise(tensor, idx):\n",
        "    g = torch.Generator()\n",
        "    salt = 275991\n",
        "    g.manual_seed(salt + idx)\n",
        "    tensor = tensor + torch.normal(mean=0.5, std=0.5, size=tensor.size(), generator=g)\n",
        "    tensor = torch.clip(tensor, 0, 1)\n",
        "    return tensor\n",
        "\n",
        "\n",
        "class MnistForAuto(torch.utils.data.Dataset):\n",
        "  def __init__(self, dataset, noisy):\n",
        "    self.dataset = dataset\n",
        "    self.noisy = noisy\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    img, _ = self.dataset[idx]\n",
        "    \n",
        "    target = img\n",
        "    if self.noisy:\n",
        "      img = add_noise(target, idx)\n",
        "    \n",
        "    return img, target\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "\n",
        "\n",
        "def get_mnist_dataloader(train, noisy: bool):\n",
        "    transforms = [torchvision.transforms.ToTensor(),]\n",
        "    mnist = MNIST('files/', train=train, download=True,\n",
        "                  transform=torchvision.transforms.Compose(transforms))\n",
        "    mnist_for_auto = MnistForAuto(mnist, noisy)\n",
        "    return DataLoader(mnist_for_auto, batch_size=batch_size, shuffle=train, num_workers=4)\n",
        "\n",
        "\n",
        "dataloader_tr = get_mnist_dataloader(train=True, noisy=False)\n",
        "dataloader_test = get_mnist_dataloader(train=False, noisy=False)"
      ],
      "metadata": {
        "id": "w_XKHLQZ6d3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs, targets = next(iter(dataloader_tr))\n",
        "\n",
        "def show(imgs):\n",
        "  grid = torchvision.utils.make_grid(imgs[:8])\n",
        "  plt.imshow(grid.numpy().transpose([1, 2, 0]))\n",
        "  plt.show()\n",
        "\n",
        "show(imgs)\n",
        "show(targets)"
      ],
      "metadata": {
        "id": "hQS7ooWe6gBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Convolutional autoencoder\n",
        "Network:\n",
        "- 3x3 Conv2d, filters=16, stride=2, relu, padding=\n",
        "- 3x3 Conv2d filters=8, stride=2, relu, padding=\n",
        "- 3x3 Conv2d filters=8, stride=2, relu, padding=\n",
        "- 3x3 Conv2d filters=8, relu, padding=\n",
        "- 2x2 UpsamplingBilinear2d\n",
        "- 3x3 Conv2d filters=8, relu, padding=\n",
        "- 2x2 UpsamplingBilinear2d\n",
        "- 3x3 Conv2d filters=16, relu, padding=\n",
        "- 2x2 UpsamplingBilinear2d\n",
        "- 3x3 Conv2d filters=1, sigmoid, padding=\n",
        "\n",
        "and train it with Adam and binary_crossentropy.\n",
        "\n",
        "Question: What is the size of the input, output and compressed representations?"
      ],
      "metadata": {
        "id": "aRTxbLv8X7mB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AutoencoderNet1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        (...)\n",
        "\n",
        "    def forward(self, x):\n",
        "        latent = self.encoder(x)\n",
        "        x = self.decoder(latent)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ksr6YKxj6imI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderDecoderModel(pl.LightningModule):\n",
        "    def __init__(self, net):\n",
        "        super(EncoderDecoderModel, self).__init__()\n",
        "        self._net = net\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self._net(x)\n",
        "        return x\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        z = self._net.encoder(x)\n",
        "        x_hat = self._net.decoder(z)\n",
        "        loss = self.compute_loss(x_hat, y)\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        x_hat = self(x)\n",
        "        loss = self.compute_loss(x_hat, y)\n",
        "        self.log('val_loss', loss)\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        (...)\n",
        "\n",
        "    def compute_loss(self, x_hat, x):\n",
        "        (...)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        x_hat = self(x)\n",
        "        loss = self.compute_loss(x_hat, y)\n",
        "        self.log('test_loss', loss)\n",
        "        num_imgs = 6\n",
        "        grid_in = torchvision.utils.make_grid(x[:num_imgs])\n",
        "        grid_out = torchvision.utils.make_grid(x_hat[:num_imgs])\n",
        "        grid_target = torchvision.utils.make_grid(y[:num_imgs])\n",
        "        self.logger.experiment.add_image('input', grid_in)\n",
        "        self.logger.experiment.add_image('output', grid_out)\n",
        "        self.logger.experiment.add_image('target', grid_target)"
      ],
      "metadata": {
        "id": "KhRPJrXR6kZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(model, dataloader_tr, dataloader_test):\n",
        "    logger = TensorBoardLogger(\"runs\", name=\"my_model\")\n",
        "    trainer = pl.Trainer(limit_test_batches=1, limit_val_batches=10, max_epochs=epochs, logger=logger, accelerator=device, devices=1)\n",
        "    trainer.fit(model=model, train_dataloaders=dataloader_tr, val_dataloaders=dataloader_test)\n",
        "    trainer.test(model=model, dataloaders=dataloader_test)"
      ],
      "metadata": {
        "id": "N9ip-JgY6lUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = EncoderDecoderModel(AutoencoderNet1())\n",
        "run_experiment(model, dataloader_tr, dataloader_test)"
      ],
      "metadata": {
        "id": "Z_bsytn26nSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Denoising Autoencoder\n",
        "\n",
        "Let's generate synthetic noisy digits applying a gaussian noise matrix and clipping images between 0 and 1."
      ],
      "metadata": {
        "id": "Ctim2AZkYkNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader_tr_noisy = get_mnist_dataloader(train=True, noisy=True)\n",
        "dataloader_test_noisy = get_mnist_dataloader(train=False, noisy=True)"
      ],
      "metadata": {
        "id": "itTkbcpbYwR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs, targets = next(iter(dataloader_tr_noisy))\n",
        "\n",
        "show(imgs)\n",
        "show(targets)"
      ],
      "metadata": {
        "id": "mvWOUgUNY3jM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's define a network:\n",
        "- 3x3 Conv2d, filters=32, stride=2, relu, padding=\n",
        "- 3x3 Conv2d, filters=32, stride=2, relu, padding=\n",
        "- 3x3 Conv2d, filters=32, relu, padding=\n",
        "- 2x2 UpsamplingBilinear2d\n",
        "- 3x3 Conv2d, filters=32, relu, padding=\n",
        "- 2x2 UpsamplingBilinear2d\n",
        "- 3x3 Conv2d, filters=1, sigmoid, padding=\n",
        "\n",
        "and train it with Adam and binary_crossentropy.\n",
        "\n",
        "Question: What is the size of the input, output and compressed representations?"
      ],
      "metadata": {
        "id": "AVSf_gtcXzPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AutoencoderNet2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        (...)\n",
        "\n",
        "    def forward(self, x):\n",
        "        latent = self.encoder(x)\n",
        "        x = self.decoder(latent)\n",
        "        return x"
      ],
      "metadata": {
        "id": "qIxtArGZ6oUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = EncoderDecoderModel(AutoencoderNet2())\n",
        "run_experiment(model, dataloader_tr_noisy, dataloader_test_noisy)"
      ],
      "metadata": {
        "id": "b9gkzDoK6pfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls runs"
      ],
      "metadata": {
        "id": "_thD07-E8u4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -r runs"
      ],
      "metadata": {
        "id": "sT4hUo889LVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "l7IcmnoO80Mo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "sZniGxbA81cn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}