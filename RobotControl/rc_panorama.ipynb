{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U6TnRAPiFgeg",
    "outputId": "6941fa9a-9069-456e-a50e-abdef1165add",
    "ExecuteTime": {
     "end_time": "2023-11-28T15:30:46.631785Z",
     "start_time": "2023-11-28T15:30:46.618958Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2.cv2'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/rp/617gz73x3b93d8v2hszwskkw0000gn/T/ipykernel_86895/534673267.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mcv2\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"OpenCV version is: {cv2.__version__}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;31m# In Colab we need to use:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.8/site-packages/cv2/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0msys\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mcv2\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mcv2\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0m_registerMatType\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mmat_wrapper\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'cv2.cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "print(f\"OpenCV version is: {cv2.__version__}\")\n",
    "\n",
    "# In Colab we need to use:\n",
    "from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dO7BbVuSF0ds",
    "outputId": "af35f2af-2c2f-42e7-9e24-25a85055055a",
    "ExecuteTime": {
     "start_time": "2023-11-28T15:30:40.924339Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd /content/\n",
    "!rm -rf rc-2023-24\n",
    "!git clone https://github.com/mim-uw/rc-2023-24.git\n",
    "%cd rc-2023-24/docs/lab5-public/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L7hDVuagGDbZ",
    "ExecuteTime": {
     "start_time": "2023-11-28T15:30:41.401136Z"
    }
   },
   "outputs": [],
   "source": [
    "# Camera parameteres\n",
    "camera_matrix = np.array([\n",
    "    [1.28613634e+03, 0.00000000e+00, 6.92097797e+02],\n",
    "    [0.00000000e+00, 1.30040995e+03, 4.25368745e+02],\n",
    "    [0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
    "])\n",
    "\n",
    "dist_coeffs = np.array(\n",
    "    [[-0.30566098, -0.17641842, -0.00495141, -0.00106297, 0.72164286]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8QRldr4PKZ_x",
    "outputId": "53f50fd2-5879-4f3a-a770-798906600d8b",
    "ExecuteTime": {
     "start_time": "2023-11-28T15:30:41.402176Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate undistorted camera matrix\n",
    "\n",
    "# OpenCV order\n",
    "img = cv2.imread(\"hw11.jpg\")\n",
    "size = (img.shape[1], img.shape[0])\n",
    "\n",
    "alpha = 0.\n",
    "rect_camera_matrix = cv2.getOptimalNewCameraMatrix(camera_matrix, dist_coeffs, size, alpha)[0]\n",
    "\n",
    "# Calculate undistortion maps\n",
    "map1, map2 = cv2.initUndistortRectifyMap(camera_matrix, dist_coeffs, np.eye(3), rect_camera_matrix, size, cv2.CV_32FC1)\n",
    "\n",
    "undistorted_imgs = []\n",
    "\n",
    "# Undistort the photos\n",
    "for i in range(1, 5):\n",
    "    img = cv2.imread(\"hw1\" + str(i) + \".jpg\")\n",
    "\n",
    "    # Use maps to undistort an image\n",
    "    rect_img = cv2.remap(img, map1, map2, cv2.INTER_LINEAR)\n",
    "\n",
    "    # Show original and undistorted side by side\n",
    "    cv2_imshow(cv2.hconcat([img, rect_img]))\n",
    "\n",
    "    undistorted_imgs.append(rect_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z7r9-C_sNvDS",
    "ExecuteTime": {
     "start_time": "2023-11-28T15:30:41.402431Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function for finding and displaying aruco markers\n",
    "def find_aruco_markers(dictionary, img):\n",
    "    detectorParams = cv2.aruco.DetectorParameters()\n",
    "    detectorParams.cornerRefinementMethod = cv2.aruco.CORNER_REFINE_CONTOUR\n",
    "    detector = cv2.aruco.ArucoDetector(dictionary, detectorParams)\n",
    "\n",
    "    img_draw = img.copy()\n",
    "    corners, ids, _ = detector.detectMarkers(img)\n",
    "\n",
    "    # inspect the image and draw detection\n",
    "    RED = (0, 0, 255)\n",
    "    cv2.aruco.drawDetectedMarkers(img_draw, corners, borderColor=RED)\n",
    "    cv2_imshow(img_draw)\n",
    "\n",
    "    return corners, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HLZjYkodOIx8",
    "outputId": "3caf4284-c46e-480e-daf6-45796e1e7527"
   },
   "outputs": [],
   "source": [
    "dictionary = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_250)\n",
    "corners_ls = []\n",
    "ids_ls = []\n",
    "for img in undistorted_imgs:\n",
    "    corners, ids = find_aruco_markers(dictionary, img)\n",
    "    corners_ls.append(corners)\n",
    "    ids_ls.append(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "subset_of_imgs = np.array([0, 1, 2]) # define the subset of size 3, for instance [0, 2, 3]\n",
    "corners_ls = np.array(corners_ls)[subset_of_imgs]\n",
    "ids_ls = np.array(ids_ls)[subset_of_imgs]\n",
    "\n",
    "# TODO find the correct sequence of imgs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-28T15:30:41.402613Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def find_nearest_neighbor(p, shape):\n",
    "    pos_x = np.array([np.floor(p[0]), np.ceil(p[0])])\n",
    "    pos_y = np.array([np.floor(p[1]), np.ceil(p[1])])\n",
    "    # find the nearest neighbor\n",
    "    min_dis = np.inf\n",
    "    x_min, y_min = 0, 0\n",
    "    for x in pos_x:\n",
    "        for y in pos_y:\n",
    "            dis, x_aux, y_aux = np.inf, 0, 0\n",
    "            if 0 <= x < shape[0] and 0 <= y < shape[1]:\n",
    "                dis = np.sqrt((p[0] - x) ** 2 + (p[1] - y) ** 2)\n",
    "                x_aux, y_aux = x, y\n",
    "            elif 0 <= x < shape[0]:\n",
    "                if y >= shape[1]:\n",
    "                    dis = np.abs(p[1] - shape[1] + 1)\n",
    "                    x_aux, y_aux = x, shape[1] - 1\n",
    "                else:\n",
    "                    dis = np.abs(p[1])\n",
    "                    x_aux, y_aux = x, 0\n",
    "            elif 0 <= y < shape[1]:\n",
    "                if x >= shape[0]:\n",
    "                    dis = np.abs(p[0] - shape[0] + 1)\n",
    "                    x_aux, y_aux = shape[0] - 1, y\n",
    "                else:\n",
    "                    dis = np.abs(p[0])\n",
    "                    x_aux, y_aux = 0, y\n",
    "            else:\n",
    "                corners_x = [0, shape[0] - 1]\n",
    "                corers_y = [0, shape[1] - 1]\n",
    "                for c_x in corners_x:\n",
    "                    for c_y in corers_y:\n",
    "                        dis_aux = np.sqrt((p[0] - c_x) ** 2 + (p[1] - c_y) ** 2)\n",
    "                        if dis_aux < dis:\n",
    "                            dis = dis_aux\n",
    "                            x_aux, y_aux = c_x, c_y\n",
    "            if dis < min_dis:\n",
    "                min_dis = dis\n",
    "                x_min, y_min = x_aux, y_aux\n",
    "\n",
    "    return int(x_min), int(y_min)\n",
    "\n",
    "def proj_trans(img, trans_mat, width):\n",
    "    cv2_imshow(img)\n",
    "    inv_trans_mat =  np.linalg.inv(trans_mat)\n",
    "    # create a grid of points\n",
    "    x, y = np.meshgrid(np.arange(img.shape[0]), np.arange(width))\n",
    "    # create a matrix of points\n",
    "    points = np.vstack((x.flatten(), y.flatten(), np.ones(img.shape[0] * width)))\n",
    "    # apply the homography transformation\n",
    "    points = inv_trans_mat @ points\n",
    "    points = points / points[2, :]\n",
    "    n_x, n_y = [], []\n",
    "    for p in points.T:\n",
    "        p_x, p_y = find_nearest_neighbor(p, img.shape)\n",
    "        n_x.append(p_x)\n",
    "        n_y.append(p_y)\n",
    "    img_transformed = np.zeros((img.shape[0], width, 3), dtype=np.uint8)\n",
    "    img_transformed[x.flatten(), y.flatten()] = img[n_x, n_y]\n",
    "    cv2_imshow(img_transformed)\n",
    "\n",
    "    return img_transformed"
   ],
   "metadata": {
    "id": "oi8YBISlcOcQ",
    "ExecuteTime": {
     "start_time": "2023-11-28T15:30:41.402742Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "proj_trans(img, np.array([[1., 0., 1.], [2., 1., 1.], [0., 0., 1.]]), 2 * img.shape[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Find homography matrix based on shared points using linalg.svd\n",
    "def find_homography(shared_points):\n",
    "    A = np.zeros((2 * len(shared_points), 9))\n",
    "    for i in range(len(shared_points)):\n",
    "        x1, y1 = shared_points[i][0][0], shared_points[i][0][1]\n",
    "        x2, y2 = shared_points[i][1][0], shared_points[i][1][1]\n",
    "        A[2 * i] = np.array([x1, y1, 1, 0, 0, 0, -x1 * x2, -x2 * y1, -x2])\n",
    "        A[2 * i + 1] = np.array([0, 0, 0, x1, y1, 1, -x1 * y2, -y2 * y1, -y2])\n",
    "    _, _, V = np.linalg.svd(A)\n",
    "\n",
    "    return V[-1].reshape(3, 3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def random_tests_for_find_homography(number_of_tests):\n",
    "    for t_n in range(number_of_tests):\n",
    "        H = np.random.randn(3, 3)\n",
    "        first_img_points = np.random.randn(2, 5)\n",
    "        first_img_points = np.vstack((first_img_points, np.ones(5)))\n",
    "        second_img_points = H @ first_img_points\n",
    "        second_img_points = second_img_points / second_img_points[2]\n",
    "        aux_shared_points = np.vstack((first_img_points[:2], second_img_points[:2]))\n",
    "        shared_points = []\n",
    "        for i in range(5):\n",
    "            shared_points.append(aux_shared_points[:, i].reshape(2, 2))\n",
    "        shared_points = np.array(shared_points)\n",
    "        found_h = find_homography(shared_points)\n",
    "        scale = H / found_h # the homography is the same up to a scaling factor\n",
    "        assert(np.allclose(np.ones((3, 3)), scale / scale[0, 0]))\n",
    "        print(f\"TEST {t_n}: OK\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Run tests for the homography implementation\n",
    "random_tests_for_find_homography(number_of_tests=100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# points shared between hw11.jpg and hw12.jpg for TASK 4\n",
    "shared_points = np.array([[[466, 131], [449, 562]], [[472, 131], [455, 562]], [[466, 137], [449, 568]], [[472, 137], [455, 568]], [[472, 133], [455, 564]]])\n",
    "hom = find_homography(shared_points)\n",
    "hw12_trans = proj_trans(undistorted_imgs[1], hom, 1960)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# stitch two images as a panorama where the overlapping region is the average of the two images\n",
    "def panorama_without_weighted_average(img1, img2):\n",
    "    stitched_img = np.zeros((img1.shape[0], img2.shape[1], 3), dtype=np.uint8)\n",
    "    stitched_img[:, :img1.shape[1], :] = img1\n",
    "    stitched_img += img2\n",
    "    stitched_img[:, :img1.shape[1], :] //= 2\n",
    "\n",
    "    return stitched_img"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cv2_imshow(panorama_without_weighted_average(undistorted_imgs[0], hw12_trans))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# stitch two images as a panorama where the overlapping region is a weighted average of the two images\n",
    "# depending on the distance from the center of the overlapping region\n",
    "def panorama_with_weighted_average(img1, img2):\n",
    "    stitched_img = np.zeros((img1.shape[0], img2.shape[1], 3), dtype=np.uint8)\n",
    "    x_1, y_1 = np.meshgrid(np.arange(img1.shape[1]), np.arange(img1.shape[0]))\n",
    "    x_2, y_2 = x_1, y_1\n",
    "    x_1 -= img1.shape[0] // 2\n",
    "    y_1 -= img1.shape[1] // 2\n",
    "    x_1, y_1 = x_1 ** 2, y_1 ** 2\n",
    "    x_2 -= img2.shape[0] // 2\n",
    "    y_2 -= img2.shape[1] // 2\n",
    "    x_2, y_2 = x_2 ** 2, y_2 ** 2\n",
    "    z_1 = x_1 + y_1\n",
    "    z_2 = x_2 + y_2\n",
    "    z_1 = z_1 / (z_1 + z_2)\n",
    "    z_2 = z_2 / (z_1 + z_2)\n",
    "    for c in range(3):\n",
    "        stitched_img[:, :img1.shape[1], c] = img1[:, :, c] * z_2 + img2[:, :img1.shape[1], c] * z_1\n",
    "\n",
    "    stitched_img[:, img1.shape[1]:, :] = img2[:, img1.shape[1]:, :]\n",
    "\n",
    "    return stitched_img"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cv2_imshow(panorama_with_weighted_average(undistorted_imgs[0], hw12_trans))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
